{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae0cb07c-1bcc-45f4-a11a-e7aa6a2997c4",
   "metadata": {},
   "source": [
    "# Word Count Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaf8d03-40bd-4c5b-83bb-83f98aa39173",
   "metadata": {},
   "source": [
    "Very often an output of a MapReduce Job is an input for another MapReduce Job. MRJob has a concept of `steps` to achieve exactly that.\n",
    "\n",
    "See the official [website](https://mrjob.readthedocs.io/en/latest/guides/quickstart.html#writing-your-second-job) for more information."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e7b0d84-8905-4c47-81b4-ebcd4857e4d1",
   "metadata": {},
   "source": [
    "The template for a step pipeline, here with two steps:\n",
    "- step1: with a mapper, a combiner and a reducer\n",
    "- step2: with just a mapper and a reducer\n",
    "\n",
    "looks like the following\n",
    "\n",
    "```python\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class MyJob(MRJob):\n",
    "\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper=self.mapper_one,\n",
    "                   combiner=self.combiner_one,\n",
    "                   reducer=self.reducer_one),\n",
    "            MRStep(mapper=self.mapper_two, reducer=self.reducer_two)\n",
    "        ]\n",
    "\n",
    "    def mapper_one(self, _, line):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def combiner_one(self, key, counts):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def reducer_one(self, key, counts):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def mapper_two(self, key, counts):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def reducer_two(self, key, counts):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MyJob.run()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a653307c-c7c2-42d4-9969-33419d72eae3",
   "metadata": {},
   "source": [
    "## Your Solution\n",
    "Try to implement a sorted wordcount with two steps. In the first step you do the normal wordcount. What should you implement for the second step?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515bce7f-1f47-4380-bf59-b5a1191ccc03",
   "metadata": {},
   "source": [
    "## Sorting Behavior in Hadoop\n",
    "If you want to control the sorting behavior before the reducing phase for a step, then you have to give a `JobConf` for this step:\n",
    "```python\n",
    "def steps(self):\n",
    "        JOBCONF_STEP2 = {\n",
    "            'mapred.output.key.comparator.class':'org.apache.hadoop.mapred.lib.KeyFieldBasedComparator',\n",
    "            'mapred.text.key.comparator.options':'-nr',\n",
    "        }\n",
    "        return [\n",
    "            MRStep(mapper=self.mapper,\n",
    "                   combiner=self.combiner,\n",
    "                   reducer=self.reducer),\n",
    "            MRStep(jobconf=JOBCONF_STEP2, mapper=self.mapper_two, reducer=self.two)]\n",
    "```\n",
    "\n",
    "This would sort the keys numerically and in descending order. Note, however, this will only work when you run `MrJob` in the `hadoop` mode and not in `local` mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d2e3b-d54a-46c4-a92b-ccd08820f519",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile wc.py\n",
    "\n",
    "#!/usr/bin/python3\n",
    "\n",
    "# your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaf5ba4-6cab-4956-ab0d-896db57109d2",
   "metadata": {},
   "source": [
    "## Testing the Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772f6837-62e4-4c0c-9a1a-155909bb21f4",
   "metadata": {},
   "source": [
    "### Locally (no sorting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ebf7eb-0840-4d59-bba2-496809c32972",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python wc.py /data/dataset/text/small.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9d4e3f-b1cd-4fe9-bf38-0e1b778dbfc2",
   "metadata": {},
   "source": [
    "### On Hadoop - Results on Console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7151404b-955d-4f41-a7a0-2b2b721c85b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python wc.py -r hadoop hdfs:///dataset/text/small.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f9dc11-2614-4f90-a445-b3c28dfb5a0e",
   "metadata": {},
   "source": [
    "### On Hadoop - Results are Written to HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01357fd-32fe-4fce-b0ad-68f0e8ad3eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python wc.py -r hadoop hdfs:///dataset/text/small.txt --output-dir hdfs:///results/wordcount/sorted/small --no-output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17945f3a-2f1a-48b9-937b-f249b8062cbc",
   "metadata": {},
   "source": [
    "## Sorted WordCount for holmes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4e95c0-f4ab-4a76-9c0c-481121f021e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python wc.py -r hadoop hdfs:///dataset/text/holmes.txt --output-dir hdfs:///results/wordcount/sorted/holmes --no-output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bbbbd8-eca0-4158-9660-a1c4f442f381",
   "metadata": {},
   "source": [
    "## Sorted WordCount for gutenberg_all.txt (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a4044f-b356-4e82-8d23-bc4ad653de39",
   "metadata": {},
   "source": [
    "Depending on the implementation, this can run for more than 30 minutes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adc7b0b-6e16-4087-8bc4-ef1e80120b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python wc.py -r hadoop hdfs:///dataset/text/gutenberg_all.txt --output-dir hdfs:///results/wordcount/sorted/gutenberg --no-output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
