{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5cef213-5bab-4905-84d1-eb95de23f9f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# MRJob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33edd851-073c-4442-8394-e436166bbbc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test if MRJob can be imported\n",
    "\n",
    "This line should execute without an error!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14e7fe9a-a7f9-4ca4-b80a-3dcd5ea44cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mrjob.job import MRJob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f4533b-68de-4914-818b-c85ea251de98",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Handling of MRJob\n",
    "\n",
    "We have to write a single python job to disk and execute it form there. However, we still make this happening inside a notebook with Jupyter's magic line `%%writefile` command.\n",
    "\n",
    "The basic template is the following\n",
    "\n",
    "```python\n",
    "%%writefile myMrTask.py\n",
    "\n",
    "#!/usr/bin/python3\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MyJob(MRJob):\n",
    "\n",
    "    def mapper(self, key, line):\n",
    "        # the mapper code\n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        # the reducer code\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MyJob.run()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ab98f5-3d22-4449-8db9-619608267011",
   "metadata": {},
   "source": [
    "### Template Explained\n",
    "\n",
    "- `%%writefile myMrTask.py`: writes the content of the cell into myMrTask.py\n",
    "- `class MyJob(MRJob):` define a class which inherits from the MRJob Class. This class contains methods that define the steps of your job.\n",
    "> A “step” consists of a mapper, a combiner, and a reducer. All of those are optional, though you must have at least one. So you could have a step that’s just a mapper, or just a combiner and a reducer.\n",
    "\n",
    "\n",
    "MRJob has a great [documentation](https://mrjob.readthedocs.io/en/latest/guides/quickstart.html#writing-your-first-job). Check it out if there are questions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff16b44-aa69-4c0a-9b56-78bbcaea0a39",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Line Counter with MrJob\n",
    "Execute the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19307e4c-fcac-4ee2-a2c0-a4d7fea07ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lineCounter.py\n",
    "\n",
    "#!/usr/bin/python3\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MyLineCounter(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        yield \"lines\", 1\n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        yield key, sum(values)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MyLineCounter.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96406531-cda2-45ec-a2ab-d261c98a251f",
   "metadata": {},
   "source": [
    "You should see the file `lineCounter.py` appearing in the folder view."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b1828e-acba-4a17-8052-b92cf6b3f74d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Executing MRJob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf12672-9059-40ad-a42a-31b0bfe65ed7",
   "metadata": {},
   "source": [
    "### Locally with a local File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6d6797-de6a-4ba5-a915-f7263d4d2db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python lineCounter.py /data/dataset/text/holmes.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5024634-7d60-43b9-a66f-83be7fe89ffd",
   "metadata": {},
   "source": [
    "### With Hadoop Services (HDFS, Yarn, MR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773c0980-c388-41cc-9884-c45557108b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python lineCounter.py -r hadoop hdfs:///dataset/text/holmes.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f677a4-1ed7-4978-8b15-cb2a26842c49",
   "metadata": {},
   "source": [
    "## Char / Line / Word - Counter\n",
    "We can emit as many key-value pairs as we like. In the `mapper` from above, we can also emit the number of characters and the number of words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f871cb0-c0d8-4d05-946c-81e52542e7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile counter.py\n",
    "\n",
    "#!/usr/bin/python3\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class MyAwesomeCounter(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        yield \"chars\", len(line)\n",
    "        yield \"words\", len(line.split())\n",
    "        yield \"lines\", 1\n",
    "\n",
    "    def reducer(self, key, values):\n",
    "        yield key, sum(values)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MyAwesomeCounter.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c789920c-e8eb-4b07-b106-b21a1c208a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python counter.py /data/dataset/text/holmes.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
